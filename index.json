[{"authors":["admin"],"categories":null,"content":"I'm currently completing my compulsory internship at Volkswagen AG in Germany. I'm part of the automated driving functions team, where deep learning techniques are exploited for autonomous driving. My interest in autonomous systems is what led me to pursue the master in Robotics, Systems and Control at ETH Zürich. Since starting my studies in Switzerland I had the opportunity to deepen my knowledge in many areas, such as Machine Learning/Artificial Intelligence, Computer Vision, State Estimation and Control. While doing so I also had the opportunity to develop a vision system for a snooker playing robot. Prior to my studies at ETH I obtained a B.Sc in Electronic Engineering from Politecnico di Torino. Moreover, I took part in a double degree program between my university and Tongji University allowing me to spend the second year of my bachelor in Shanghai. This experience gave me the opportunity to widen my horizon and get to know the fascinating Chinese culture. I’m deeply fascinated by technology and how it is affecting our daily life, I’m also keen on getting to know more about the business world. I’m an open minded person and I enjoy teamwork.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://cstamatiadis.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I'm currently completing my compulsory internship at Volkswagen AG in Germany. I'm part of the automated driving functions team, where deep learning techniques are exploited for autonomous driving. My interest in autonomous systems is what led me to pursue the master in Robotics, Systems and Control at ETH Zürich. Since starting my studies in Switzerland I had the opportunity to deepen my knowledge in many areas, such as Machine Learning/Artificial Intelligence, Computer Vision, State Estimation and Control.","tags":null,"title":"Constantin Stamatiadis","type":"authors"},{"authors":null,"categories":null,"content":"IfA started a project with the aim of developing a fully-autonomous billiard playing robot. The project is in its early stages. Up until now, the following tasks have been addressed: implementation of the AI through Approximate Dynamic Programming, Cue Control, and Vision and State Estimation. In this work, we focus on the latter. First, a ceiling camera was set up. Its video feed was feed into a custom image processing pipeline used to estimate the current state of the game. The pipeline first preprocesses the incoming images (remove distortion, correct perspective), then extracts the ball location through different detectors, to finally merge the measurements through a filter and give a state estimate. Second, the camera system was used to find the dynamic properties of the game, as these are essential to obtain a good model. The friction between the balls and the tablecloth was measured, as wells as the coefficient of restitution for ball collisions with other balls and with the cushions. Finally, a cue camera was set up, with the aim of getting a \"player’s eye\" view of the game. A depth camera was used in order to get ball distance measurements. The camera was located through an ArUco marker, which was also exploited to find the angular position of the cue.\n Project report\n","date":1545350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545350400,"objectID":"a27da18f061082c3b212f77268362146","permalink":"https://cstamatiadis.github.io/project/internal-project2/","publishdate":"2018-12-21T00:00:00Z","relpermalink":"/project/internal-project2/","section":"project","summary":"Vision and state estimation for the Billiard Playing Robot of the Automatic Control Lab at ETH.","tags":["Computer Vision"],"title":"DeepGreen","type":"project"},{"authors":null,"categories":null,"content":"This project was developed during the Machine Perception course at ETH Zürich. The goal was to develop a CNN architecture to perform the task of estimating eye gaze direction from single-eye images obtained by preprocessing samples from the MPIIGaze dataset. Starting from a custom architecture we tried out other famous architectures such as VGG16 and DenseNet, ending up with a custom architecture with skip connections inspired by DenseNet.\n Project report\n","date":1528934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528934400,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://cstamatiadis.github.io/project/internal-project/","publishdate":"2018-06-14T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"Applying Deep Learning techniques for Eye Gaze Estimation.","tags":["Computer Vision","Deep Learning"],"title":"Eye Gaze Estimation","type":"project"}]